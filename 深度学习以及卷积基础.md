# 深度学习以及卷积基础

翻译： 石文华

---
 文章来自：https://leonardoaraujosantos.gitbooks.io
 作者：Leonardo Araujo dos Santos

## 介绍
![image.png-56.2kB][1]


  深度学习是机器学习的一个分支，是基于数据来学习表示数据的一组算法。下面我们列出最受欢迎的一些深度学习算法。
  
  - **卷积神经网络**
  - **深度信念网络**
  - **自动编码器**
  - **递归神经网络（RNN / LSTM / GRU）**
  - **对抗生成网络（GAN）**
深度学习的目的之一是他们将取代手工制作的特征提取。这个想法是，他们将从给定的数据中“学习”到所需的最佳特征。
![image.png-282.5kB][2]


 ## 层和层
 深度学习模型由多层构成，在人工神经网络的情况下，具有2个以上隐藏层的多层感知器（MLP）已经是深度模型。
作为一个经验法则，深层模型有可能比浅层模型表现更好。但是，越深的神经网络你需要越多的数据来避免过拟合。
![image.png-93.4kB][3]


## 层类型
这里列出一些最常用的图层 

1.卷积层
2.最大/平均池化层
3.Dropout层
4.批量标准化层
5.全连接层
6.Relu，Tanh，Sigmoid层（非线性层）
7.Softmax，交叉熵，SVM，欧几里得（损失层）
## 避免过拟合（正则化）
除了获得更多的数据之外，还有一些技巧用于解决过度拟合问题，这里列出了一些最常见的技术：

- **Dropout**
- **L2正则化**
- **数据增强**

## Dropout
这是一种在训练期间随机关闭全连接层中一些神经元的技术。
![image.png-343.4kB][4]


  Dropout迫使全连接层以不同的方式学习相同的概念。

## L2正则化
  最常见的正则化形式是L2正则化，L2正则化是给损失函数添加一个额外的惩罚项，这个惩罚项也就是我们正在优化的所有权重/参数的平方值。对于神经网络的每一个参数ω,我们加入一项0.5λω²到损失函数中去，λ表示正则化强度的参数，当我们反向传播计算导数时，我们只是用了0.5λ作为正则化的强度。由于使用这种正规化，非常高价值的权重受到严重惩罚。所以我们更倾向于使用一层的所有权重作为输入，而不是少数一些权重带替代。这种方法的效果比较好，因为我们的模型权重将被最大限度地利用，并且我们有更少未使用的权重。

除了L2正则化之外，还有L1正则化和Max Norm，但这里没有讨论，因为L2一般表现更好。

## 数据增强
通过对输入数据进行一些转换，可以合成新的训练样例。例如，进行图像翻转或随机移动RGB值。在2012年Imagenet竞赛期间，Alex Krizhevesky（Alexnet）使用了2048倍的因子进行数据增强，这意味着用于训练其模型的数据集实际上比开始时大2048倍，并且在不使用数据增强的情况下改进了泛化。
![image.png-212.4kB][5]


![image.png-177.9kB][6]


## 分层的特征表示
它是让学习算法找到从输入到更深层的最佳表示。
浅层学会用简单的形式表示数据，深层用前面学到的特征来学习更高纬度的特征来表示数据。
![image.png-84.9kB][7]


![image.png-225.3kB][8]


## 卷积
卷积是一种数学运算，它对两个函数（信号）乘积进行积分，其中一个信号是被翻转。例如下面我们对2个信号f（t）和g（t）进行卷积。
![image.png-129kB][9]


首先要做的是水平翻转（180度）信号g，然后将翻转后的g滑过f，对应相乘并累加所有的值。
conv（a，b）== conv（b，a）的结果是一样的，
在这种情况下，规定蓝色信号  F（τ）F（τ）  是我们的输入信号和  G（t ）G（Ť）  作为我们的卷积核，当使用卷积来过滤信号时使用术语卷积核。

## 输出一维信号
在一维卷积的情况下，输出尺寸计算如下：
outputSize=(InputSize−KernelSize)+1

## 卷积的应用
人们在以下用例中对信号处理使用卷积：

- **滤波器信号（1D音频，2D图像处理）**
- **检查一个信号与另一个信号的相关程度**
- **在信号中查找模式**  

## 在matlab和python（numpy）中的简单例子
下面我们将两个信号x =（0,1,2,3,4）与w =（1，-1,2）进行卷积。
![image.png-6.8kB][10]


![image.png-18.8kB][11]
  


## 手工操作
为了更好地理解卷积的概念，我们手工完成上面的例子。我们要卷积2个信号（x，w）。首先是水平翻转W（或向左旋转180度）
![image.png-11.8kB][12]


 之后，我们将翻转的W滑过输入X.
 ![image.png-54.1kB][13]


  注意到在步骤3,4,5中，翻转后的窗口完全位于输入信号的内部。称为“有效”卷积。在翻转窗口不完全位于输入窗口（X）内部的情况下，我们可以将其视为零，只计算位于窗口内的数据，例如在步骤1中，我们将1乘以零，其余部分将被忽略。
## 对输入进行填充
为了保持卷积结果大小与输入大小相同，并避免称为循环卷积的效应，我们用零填充信号。
你把零放在哪个位置取决于你想要做什么，例如：在1D的情况下，你可以在每一端连接它们，但在2D上它通常放置在原始信号周围。
![image.png-2.8kB][14]


![image.png-8.8kB][15]


  在matlab上，你可以使用命令'padarray'来填充输入信号：
    \>> x

x(:,:,1) =

     1     1     0     2     0
     2     2     2     2     1
     0     0     0     2     1
     2     2     2     2     1
     2     0     2     2     1


x(:,:,2) =

     2     1     0     0     0
     0     2     0     1     0
     1     0     1     2     0
     1     2     0     2     1
     1     2     1     2     2


x(:,:,3) =

     2     1     1     2     2
     1     1     1     0     0
     2     0     1     0     2
     0     2     0     2     1
     0     0     2     1     0

\>> padarray(x,[1 1])

ans(:,:,1) =

     0     0     0     0     0     0     0
     0     1     1     0     2     0     0
     0     2     2     2     2     1     0
     0     0     0     0     2     1     0
     0     2     2     2     2     1     0
     0     2     0     2     2     1     0
     0     0     0     0     0     0     0


ans(:,:,2) =

     0     0     0     0     0     0     0
     0     2     1     0     0     0     0
     0     0     2     0     1     0     0
     0     1     0     1     2     0     0
     0     1     2     0     2     1     0
     0     1     2     1     2     2     0
     0     0     0     0     0     0     0


ans(:,:,3) =

     0     0     0     0     0     0     0
     0     2     1     1     2     2     0
     0     1     1     1     0     0     0
     0     2     0     1     0     2     0
     0     0     2     0     2     1     0
     0     0     0     2     1     0     0
     0     0     0     0     0     0     0

## 将卷积转化为计算图
将操作转化为计算图，更容易计算每个节点参数的偏导数，这里我们演示将之前的一维卷积转化为计算图，这也可以扩展到二维卷积。
![image.png-74.7kB][16]


  计算图的创建是在翻转的内核完全插入被卷积的数据之前的。
  ![image.png-91.5kB][17]


  之后我们将使用这个图来推断卷积层的输入（x）和权重（w）的梯度。
## 2D卷积
现在我们延伸到第二个维度。2D卷积被用作图像滤波器。下面是一个2D图像卷积的例子：
![image.png-90.1kB][18]
  
  


## Matlab和python示例
![image.png-7.2kB][19]


## 手工操作
首先，我们应该翻转内核，然后在输入信号上滑动内核。
![image.png-23.2kB][20]
![image.png-43.3kB][21]
## 步长
默认情况下，当我们进行卷积运算时，我们的窗口每次移动一个像素（步幅= 1），但是在卷积神经网络中我们需要移动多个像素。例如，在使用大小为2的内核进行卷积时，我们将使用2的步幅。将步幅和内核大小都设置为2将导致输出沿着两个维度恰好为输入大小的一半。
观察红色内核窗口下方的移动远远多于一个像素。
![image.png-53.5kB][22]
## 2D的输出尺寸
下面提供了一个公式计算我们卷积之后的输出尺寸
如果我们考虑将由P填充的空间大小[H，W]的输入与大小为F的方形核并使用步长S进行卷积，那么卷积的输出大小被定义为：
![image.png-10.1kB][23]
F是内核的大小，通常我们使用方形内核，所以F既是内核的宽度又是高度
## 实现卷积运算
下面的示例将对一个5x5x3的输入进行卷积，其中具有以下参数Stride=2,Pad=1，F=3（3x3内核）和K=2（两个滤波器）的conv层。
我们的输入有3个通道，所以需要3x3x3的内核权重。有2个过滤器（K = 2），所以最后会有2个输出。计算这两个输出的大小为：（5 - 3 + 2）/ 2 + 1 = 3。得到最终的尺寸（3x3x2）。

![image.png-106.6kB][24]
仔细看看这个例子，我们需要计算2个卷积，不要忘了给每个3x3x3滤波器（w0，w1）添加偏差。
![image.png-13.8kB][25]
## 参考文献
-  **https://en.wikipedia.org/wiki/Convolution**
-  **https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution**
-  **http://www.dspguide.com/ch6/2.htm**


  [1]: http://static.zybuluo.com/Team/nuvfi0qp49om92cn3mi16e3j/image.png
  [2]: http://static.zybuluo.com/Team/87uobqz4x4g1ddew4otl0j2x/image.png
  [3]: http://static.zybuluo.com/Team/chj7sbbl3gvpa9wp89742dkh/image.png
  [4]: http://static.zybuluo.com/Team/r1k3734cgwu4jz4i3wptac84/image.png
  [5]: http://static.zybuluo.com/Team/fj3n7s6mk7rnzp4abs6axs9c/image.png
  [6]: http://static.zybuluo.com/Team/vczys1zj7kxhyee1t2em1qbb/image.png
  [7]: http://static.zybuluo.com/Team/1gmj6v96hwkc2vl4tkp9r0x1/image.png
  [8]: http://static.zybuluo.com/Team/j0ihgcgyzgqhvlvjcbxth6rs/image.png
  [9]: http://static.zybuluo.com/Team/9nbqw5fwd6oltgkdze98p76n/image.png
  [10]: http://static.zybuluo.com/Team/5w3wa8zilplnhjyayy4crwu0/image.png
  [11]: http://static.zybuluo.com/Team/v232nh7x78m4jxfrzfudmz0v/image.png
  [12]: http://static.zybuluo.com/Team/5s2bbflbcp210niax90469h1/image.png
  [13]: http://static.zybuluo.com/Team/farxtnij1en3tpzmn99nr4mj/image.png
  [14]: http://static.zybuluo.com/Team/9yzv9svldxdv0ry5a71atwzn/image.png
  [15]: http://static.zybuluo.com/Team/y387sxqq92h8sfpjdywlyzoc/image.png
  [16]: http://static.zybuluo.com/Team/oyt9lwbfudrsri838su07gow/image.png
  [17]: http://static.zybuluo.com/Team/0tvs487qeea7towzncixu5za/image.png
  [18]: http://static.zybuluo.com/Team/sfg933kio0cl130efsuf7m60/image.png
  [19]: http://static.zybuluo.com/Team/21ynf60mhk6alcenrwughn7s/image.png
  [20]: http://static.zybuluo.com/Team/ot8gqxp9tyc7trqgp531uxy0/image.png
  [21]: http://static.zybuluo.com/Team/7nh5at2dlprflmk30yp242pf/image.png
  [22]: http://static.zybuluo.com/Team/mj4u5q1fjrsv41wjxzw73zk0/image.png
  [23]: http://static.zybuluo.com/Team/m6mxxvjusmnz54alq1m8740e/image.png
  [24]: http://static.zybuluo.com/Team/xdtt54bo357oijl6yly9kwvh/image.png
  [25]: http://static.zybuluo.com/Team/zcutdqx6nkmp4pxo5um3nnsz/image.png